{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14c053e",
   "metadata": {},
   "source": [
    "# Analyzing Delays on Caltrain\n",
    "by Ã–zge TerzioÄŸlu\n",
    "14 February 2023\n",
    "\n",
    "This is a continuation of my \"Exploring Delays on Caltrain\" notebook, where I documented my process of collecting, filtering, and merging the tweets from @Caltrain and @CaltrainAlerts about train delay on Twitter. \n",
    "\n",
    "In this notebook, we'll be analyzing Caltrain delays via the tweets and documenting preliminary data visualizations about this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b824ef6",
   "metadata": {},
   "source": [
    "## Let's import our tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10d2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import re\n",
    "import altair as alt\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a58f8d",
   "metadata": {},
   "source": [
    "### Read the local file into this notebook to be analyzed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c58dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = (r\"/Users/ozgeterzioglu/caltrain_delays_tweets/data/processed/complete_data.csv\")\n",
    "passenger_file = (r\"/Users/ozgeterzioglu/caltrain_delays_tweets/data/analysis/passenger_data.csv\")\n",
    "tweets = pd.read_csv(cwd)\n",
    "passenger_data = pd.read_csv(passenger_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c64dfc",
   "metadata": {},
   "source": [
    "## Next, we'll split the date column into day, month, year, and hour of the day for analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54eb5e8",
   "metadata": {},
   "source": [
    "### Change the date and time columns to a datetime object so we can split it into day, month, year, and hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bddc996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"created_at\"] = pd.to_datetime(tweets[\"created_at\"], format = \"%m/%d/%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"time\"] = pd.to_datetime(tweets[\"time\"], format = \"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0e6a0",
   "metadata": {},
   "source": [
    "### Insert new columns for day of week, month, year, and hour. Assign the corresponding data into each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.insert(11, \"day_of_week\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"day_of_week\"] = tweets[\"created_at\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.insert(7, \"day\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a486883",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"day\"] = tweets[\"created_at\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022aae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.insert(8, \"month\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"month\"] = tweets[\"created_at\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b336ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.insert(9, \"year\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7832d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"year\"] = tweets[\"created_at\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d767a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.insert(10, \"hour\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7197b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"hour\"] = tweets[\"time\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648af9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = tweets[\"created_at\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f882c",
   "metadata": {},
   "source": [
    "## What does our dataframe look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2028513",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639ad10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc58a4c",
   "metadata": {},
   "source": [
    "### Let's change the year data type to string to make analysis easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.astype({\"year\": \"string\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e1570",
   "metadata": {},
   "source": [
    "### Now we'll filter our data frame to exclude 2023 (since we only have about a month's worth of data from this year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2012_2022 = tweets[(tweets.year >= \"2012\") & (tweets.year <= \"2022\")]\n",
    "tweets_2012_2022.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad127d",
   "metadata": {},
   "source": [
    "### Let's clean out some extraneous/wrong station names to make our analysis accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2012_2022 = tweets_2012_2022.astype({\"station\": \"string\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = r\"\\bSFK\\b|\\bTWE\\b|\\bBAY\\b|\\bSSF\\b|\\bSBR\\b|\\bMIL\\b|\\bBWY\\b|\\bBUR\\b|\\bSMT\\b|\\bHPK\\b|\\bHIL\\b|\\bBEL\\b|\\bSCS\\b|\\bRWC\\b|\\bMPK\\b|\\bPAL\\b|\\bSTF\\b|\\bCAL\\b|\\bSAT\\b|\\bMVW\\b|\\bSUN\\b|\\bLAW\\b|\\bSCL\\b|\\bCPK\\b|\\bSJD\\b|\\bTAM\\b|\\bCAP\\b|\\bBHL\\b|\\bMHL\\b|\\bSMR\\b|\\bGIL\\b\"\n",
    "exclude = r\"@\"\n",
    "include_mask = tweets_2012_2022[\"station\"].str.contains(include)\n",
    "exclude_mask = tweets_2012_2022[\"station\"].str.startswith(exclude)\n",
    "tweets_2012_2022 = tweets_2012_2022[include_mask & ~exclude_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2012_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd2f1e",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503711e",
   "metadata": {},
   "source": [
    "### Are there any empty rows in the minutes delayed column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e94dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tweets[pd.isnull(tweets[\"clean_delay\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89c5bd",
   "metadata": {},
   "source": [
    "Hmmm... it looks like there's about 300 empty rows in the clean_delay row, which is the length of the reported train delay in minutes. It was inevitable to run into some issues filtering tweets and pulling the text from them with regular expressions. We know that I wasn't able to extract delays longer than 2 digits (e.g. 100 minutes delayed). These were pretty rare in the dataset, but still important. I reckon some of these empty rows were triple digit delays. Due to lack of time to fix this further, we will ignore these empty rows for now **(but for an accurate report, the filter.py script should be debugged to catch three digit delay lengths).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b9512",
   "metadata": {},
   "source": [
    "## Let's get started with some basic analysis! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464cebc",
   "metadata": {},
   "source": [
    "### We'll make a few .csv files so I can import them to Tableau or Flourish to create more polished visuals for publication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226a92e",
   "metadata": {},
   "source": [
    "We want to see on a large scale, the average number of delays per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_per_year = tweets_2012_2022.groupby(\"year\")[\"clean_delay\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16b39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart(delays_per_year).mark_bar().encode(\n",
    "    x = \"year\",\n",
    "    y = \"clean_delay\",\n",
    "    color = \"clean_delay\"\n",
    ").properties(\n",
    "    title = \"Number of Caltrain Delays Per Year\",\n",
    "    width = 600,\n",
    "    height = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff61aba",
   "metadata": {},
   "source": [
    "Seems like the number of delays peaked in 2019, right before the pandemic started. Delays were manually tweeted from 2012-2022. We should ask why this is. We can assume that delays dropped off in 2020 because service was reduced or cancelled due to the pandemic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16429f",
   "metadata": {},
   "source": [
    "per route:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19185e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_by_route = tweets_2012_2022.groupby(\"clean_route\")[\"clean_delay\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_by_route.to_csv(\"avg_delays_by_route.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(delays_by_route).mark_bar().encode(\n",
    "    x = \"clean_route\",\n",
    "    y = \"clean_delay\",\n",
    "    color = \"clean_delay\"\n",
    ").properties(\n",
    "    title = \"Average Caltrain Delays Per Route\",\n",
    "    width = 800,\n",
    "    height = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71690177",
   "metadata": {},
   "source": [
    "and its median counterpart in case average is wonky due to outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_by_route_median = tweets_2012_2022.groupby(\"clean_route\")[\"clean_delay\"].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff207b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_by_route_median.to_csv(\"delays_by_route.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(delays_by_route_median).mark_bar().encode(\n",
    "    x = \"clean_route\",\n",
    "    y = \"clean_delay\",\n",
    "    color = \"clean_delay\"\n",
    ").properties(\n",
    "    title = \"Median Number of Caltrain Delays Per Year\",\n",
    "    width = 800,\n",
    "    height = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a4bbd3",
   "metadata": {},
   "source": [
    "and lastly, the average number of delays by each unique day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_by_date = tweets_2012_2022.groupby(\"created_at\")[\"clean_delay\"].mean().reset_index().set_axis([\"date\", \"minutes_delayed\"], axis = 1)\n",
    "delays_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_by_date.to_csv(\"delays_by_day.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(delays_by_date).mark_bar().encode(\n",
    "    x = \"date\",\n",
    "    y = \"minutes_delayed\",\n",
    "    color = \"minutes_delayed\"\n",
    ").properties(\n",
    "    title = \"Average Number of Caltrain Delays Per Year\",\n",
    "    width = 800,\n",
    "    height = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64bc54b",
   "metadata": {},
   "source": [
    "It's going to be hard quantifying the different number of reasons per year since the way the reasons were written is not standardized, but it might be useful to have in case we find the time to standardize the reasons and produce and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab050136",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_by_year = tweets_2012_2022.groupby(\"year\")[\"delay_reason\"].value_counts()\n",
    "reason_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_by_year.to_csv(\"reason_by_year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911cdbdf",
   "metadata": {},
   "source": [
    "total number of delays per station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb66a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_delay_per_station = tweets_2012_2022.groupby(\"station\")[\"clean_delay\"].count().reset_index().set_axis([\"station\", \"delays_count\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_delay_per_station.to_csv(\"num_delays_by_station.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ec989",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alt.Chart(count_delay_per_station).mark_bar().encode(\n",
    "    x = \"station\",\n",
    "    y = \"delays_count\",\n",
    "    color = \"delays_count\"\n",
    ").properties(\n",
    "    title = \"Number of Train Delays Per Station\",\n",
    "    width = 500,\n",
    "    height = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510853fb",
   "metadata": {},
   "source": [
    "Looks like there's very little to no data for some stations. This is a key point we should ask the Caltrains spokesperson about. I know, for instance, that stations like GIL (Gilroy) there is limited service there to begin with, so delays would naturally be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c467a3d1",
   "metadata": {},
   "source": [
    "## Let's organize the number of delays by the time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_station = tweets_2012_2022.groupby([\"station\", \"created_at\",\"hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73797096",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_hour = tweets_2012_2022.groupby([\"created_at\",\"hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stationdelays_bytime.csv\", mode = \"w\") as file:\n",
    "    writer = csv.writer(file, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"station\",\"date\",\"hour\",\"avg_delay\"])\n",
    "    for station_key, station_item in grouped_station:\n",
    "        grouped_delay = grouped_station.get_group(station_key)[\"clean_delay\"].median()\n",
    "        station_name = station_key[0]\n",
    "        date = station_key[1].strftime(\"%Y-%m-%d\")\n",
    "        hour = station_key[2]\n",
    "        writer.writerow([station_name, date, hour, grouped_delay])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86295b0e",
   "metadata": {},
   "source": [
    "## Since 2012, how many tweets provided context or reasoning for the delay? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_count = tweets_2012_2022[\"delay_reason\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e0b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2012_2022.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee8589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 10420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6bfe9f",
   "metadata": {},
   "source": [
    "This is something to ask Caltrain about, why are commuters notified of the cause of the train delay only 5% of the time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a2117",
   "metadata": {},
   "source": [
    "## How many passengers were affected by delays on Caltrain from 2016-2019?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348b63a",
   "metadata": {},
   "source": [
    "Let's see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659cbb5",
   "metadata": {},
   "source": [
    "Change the column names to snake case for smooth analysis and change the data type for `year` from integer to string so it's displayed properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_data.columns = [col.lower().replace(\" \",\"_\") for col in passenger_data.columns]\n",
    "passenger_data = passenger_data.astype({\"year\": \"string\"})\n",
    "passenger_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3fd21",
   "metadata": {},
   "source": [
    "Looks like we're working with a dataset that spans from 2012-2019. Since 2012-2015 doesn't have data for the \"On Board\" column, which is the column we want to look at when quantifying how many passengers were affected by delays, we will filter out these years and do a short-term analysis instead. I know this data is missing because I created this dataset myself since I had to pull from multiple pdf files and spreadsheets to create it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c2f0fa",
   "metadata": {},
   "source": [
    "We'll also have to edit the station names to match the tweets dataframe. We'll do this because we're going to merge these two dataframes together soon and create some viz with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_passengers = passenger_data[(passenger_data.year >= \"2016\") & (passenger_data.year <= \"2019\")]\n",
    "filtered_passengers = filtered_passengers.replace({\n",
    "    'San Francisco' : 'SFK',\n",
    "    '22nd Street' : 'TWE',\n",
    "    \"Bayshore\" : \"BAY\",\n",
    "    \"South San Francisco\" : \"SSF\",\n",
    "    \"San Bruno\" : \"SBR\",\n",
    "    \"Millbrae\" : \"MIL\",\n",
    "    \"Broadway\" : \"BWY\",\n",
    "    \"Burlingame\" : \"BUR\",\n",
    "    \"San Mateo\" : \"SMT\",\n",
    "    \"Hayward Park\" : \"HPK\",\n",
    "    \"Hillsdale\" : \"HIL\",\n",
    "    \"Belmont\" : \"BEL\",\n",
    "    \"San Carlos\" : \"SCS\",\n",
    "    \"Redwood City\" : \"RWC\",\n",
    "    \"Atherton\" : \"ATH\",\n",
    "    \"Menlo Park\" : \"MPK\",\n",
    "    \"Palo Alto\" : \"PAL\",\n",
    "    \"California Avenue\" : \"CAL\",\n",
    "    \"San Antonio\" : \"SAT\",\n",
    "    \"Mountain View\" : \"MVW\",\n",
    "    \"Sunnyvale\" : \"SUN\",\n",
    "    \"Lawrence\" : \"LAW\",\n",
    "    \"Santa Clara\" : \"SCL\",\n",
    "    \"College Park\" : \"CPK\",\n",
    "    \"San Jose Diridon\" : \"SJD\",\n",
    "    \"Tamien\" : \"TAM\",\n",
    "    \"Capitol\" : \"CAP\",\n",
    "    \"Blossom Hill\" : \"BHL\",\n",
    "    \"Morgan Hill\" : \"MHL\",\n",
    "    \"San Martin\" : \"SMR\",\n",
    "    \"Gilroy\" : \"GIL\"\n",
    "    \n",
    "})\n",
    "filtered_passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71feb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(passengers_onboard).mark_line().encode(\n",
    "    x = \"year\",\n",
    "    y = \"on_board\"\n",
    ").properties(\n",
    "    title = \"Average Number of On Board Passengers Riding Caltrain from All Stations\",\n",
    "    width = 300,\n",
    "    height = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f61cb",
   "metadata": {},
   "source": [
    "The number of passengers riding Caltrain seems pretty stable between 2016-2019 and even on a slight incline. It would be more useful if we could see how ridership is affected by the pandemic. \n",
    "\n",
    "Let's compare the ridership from each station from 2016-2019 with delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed50cb7",
   "metadata": {},
   "source": [
    "We'll first filter our delays dataset for 2016-2019 to match the passenger dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967dcfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2016_2019 = tweets[(tweets.year >= \"2016\") & (tweets.year <= \"2019\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8ece8",
   "metadata": {},
   "source": [
    "Then we'll clean up our station names again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = r\"\\bSFK\\b|\\bTWE\\b|\\bBAY\\b|\\bSSF\\b|\\bSBR\\b|\\bMIL\\b|\\bBWY\\b|\\bBUR\\b|\\bSMT\\b|\\bHPK\\b|\\bHIL\\b|\\bBEL\\b|\\bSCS\\b|\\bRWC\\b|\\bMPK\\b|\\bPAL\\b|\\bSTF\\b|\\bCAL\\b|\\bSAT\\b|\\bMVW\\b|\\bSUN\\b|\\bLAW\\b|\\bSCL\\b|\\bCPK\\b|\\bSJD\\b|\\bTAM\\b|\\bCAP\\b|\\bBHL\\b|\\bMHL\\b|\\bSMR\\b|\\bGIL\\b\"\n",
    "exclude = r\"@\"\n",
    "include_mask = tweets_2016_2019[\"station\"].str.contains(include).fillna(False)\n",
    "exclude_mask = tweets_2016_2019[\"station\"].str.startswith(exclude).fillna(False)\n",
    "tweets_2016_2019 = tweets_2016_2019[include_mask & ~exclude_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7599454",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_2016_2019.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27aea4",
   "metadata": {},
   "source": [
    "Now that we're certain the station names are standardized, we'll organize our dataframe on station delays to have the number of delays reported at that station that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c02e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_per_station = tweets_2016_2019[[\"station\", \"clean_delay\", \"year\"]].copy()\n",
    "station_delays_groupby = delays_per_station.groupby([\"station\", \"year\"])\n",
    "delays_per_station = station_delays_groupby.mean().reset_index()\n",
    "delays_per_station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf12de4",
   "metadata": {},
   "source": [
    "Now, we'll merge this dataframe with the one about the average weekly number of passengers on board at each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85129d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_merged = pd.merge(delays_per_station, filtered_passengers, on = [\"station\", \"year\"])\n",
    "passenger_merged\n",
    "passenger_merged.to_csv(\"passenger_and_delays_merged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60181433",
   "metadata": {},
   "source": [
    "Let's create a viz and see roughly how many passengers were affected by delays at each station from 2016-2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2b1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart(passenger_merged).mark_bar().encode(\n",
    "    x = \"clean_delay\",\n",
    "    y = \"station\",\n",
    "    color = \"year\"\n",
    ").properties(title = \"Average Station Delays on Caltrain\", height = 500, width = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1563da",
   "metadata": {},
   "source": [
    "It's strange that 8 stations don't have any tweeted train delays for some of the years throughout 2016-2019. This would be something to ask Caltrain about and also double check our dataset for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(passenger_merged).mark_bar().encode(\n",
    "    x = \"year\",\n",
    "    y = \"on_board\",\n",
    ").properties(title = \"Average Number of Caltrain Riders 2016-2019\", height = 400, width = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982287da",
   "metadata": {},
   "source": [
    "It appears that the average number of on board passengers for Caltrain remained pretty consistent from 2016-2019. This shows that thousands of riders every week were affected by Caltrain delays, especially at 22nd Street station in San Francisco, where the most train delays were tweeted in this time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7041d80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f15ebd3f221a1facee53b815257ffdbfeb0283cf9fe39534b9eb36b2c2b1d2ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
